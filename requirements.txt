
# Core Requirements
pyspark==3.5.0        # Apache Spark Python API
numpy==1.26.0         # Numerical operations
pandas==2.1.2         # Data manipulation (useful for smaller chunks)

# Distributed Processing
dask[distributed]==2023.10.0  # Alternative for chunked processing if needed
pyarrow==13.0.0               # Efficient columnar data storage (Parquet)

# Machine Learning
scikit-learn==1.3.1           # Gaussian Mixture Model (GMM)
tensorflow==2.14.0            # For scalable GMM, if using TensorFlow
torch==2.1.0                  # For scalable GMM with PyTorch

# Data I/O
fastparquet==2024.3.0         # Writing and reading Parquet files
s3fs==2023.10.1               # Accessing S3 storage for datasets

# Utilities and Monitoring
tqdm==4.66.0                  # Progress bars
loguru==0.7.0                 # Advanced logging
pytest==7.4.0                 # Unit testing
notebook==7.1.0               # Jupyter Notebook for demonstration

# Optional Visualization (for demonstration purposes)
matplotlib==3.8.1             # Data visualization
seaborn==0.13.0               # Statistical data visualization
